# -*- coding: utf-8 -*-
"""yaqith_sentinel.absher.hakthon.AI.Anti.Agent.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Brv8rJFN--N6MZglR6Az27sPvI3vq9ss
"""

from __future__ import annotations

from dataclasses import dataclass, asdict

from typing import Literal, List, Dict, Any, Optional



import joblib

import numpy as np

import pandas as pd

ActionType = Literal["allow", "step_up", "block"]

RiskLevelType = Literal["low", "medium", "high"]





@dataclass

class LoginEvent:
    event_id: int
    user_id: int
    device_type: str
    device_id: str
    city: str
    country: str
    is_vpn: int
    is_new_device: int
    is_new_city: int
    distance_from_last_login_km: float
    hour_of_day: int
    weekday: int
    failed_logins_last_24h: int
    typing_speed_cps: float
    nav_pattern_similarity: float
    session_duration_sec: float
    past_compromised_account: int

    @classmethod
    def from_row(cls, row: pd.Series) -> "LoginEvent":
        """
        إنشاء LoginEvent مباشرة من سطر في DataFrame.
        """
        return cls(
            event_id=int(row["event_id"]),
            user_id=int(row["user_id"]),
            device_type=str(row["device_type"]),
            device_id=str(row["device_id"]),
            city=str(row["city"]),
            country=str(row["country"]),
            is_vpn=int(row["is_vpn"]),
            is_new_device=int(row["is_new_device"]),
            is_new_city=int(row["is_new_city"]),
            distance_from_last_login_km=float(row["distance_from_last_login_km"]),
            hour_of_day=int(row["hour_of_day"]),
            weekday=int(row["weekday"]),
            failed_logins_last_24h=int(row["failed_logins_last_24h"]),
            typing_speed_cps=float(row["typing_speed_cps"]),
            nav_pattern_similarity=float(row["nav_pattern_similarity"]),
            session_duration_sec=float(row["session_duration_sec"]),
            past_compromised_account=int(row["past_compromised_account"]),
        )

@dataclass

class SecurityDecision:

    """
    ناتج الوكيل الأمني بعد تقييم محاولة تسجيل الدخول.
    """
    action: ActionType              # "allow" / "step_up" / "block"
    risk_score: float               # قيمة بين 0 و 1 (احتمال الهجوم)
    risk_level: RiskLevelType       # "low" / "medium" / "high"
    reasons: List[str]              # أسباب القرار (للتفسير والـ audit)
    metadata: Dict[str, Any]        # أي بيانات إضافية (مثل user_id, device_id, country)




class YAQITHSentinelAgent:

    """
    الوكيل الأمني الرئيسي.


    - يعتمد على Pipeline مدرب ومحفوظ في ملف joblib.
    - يفترض أن الـ pipeline داخله:
        * pre-processing (اختيار الأعمدة + الترميز + الـ scaling)
        * نموذج ML يصدر predict_proba للهجوم (label = 1)
    """



    def __init__(
        self,
        model_path: str = "risk_model_pipeline.joblib",
        low_to_medium_threshold: float = 0.3,
        medium_to_high_threshold: float = 0.7,
    ) -> None:
        """
        :param model_path: مسار ملف الـ joblib اللي فيه الـ Pipeline.
        :param low_to_medium_threshold: ما تحتها يعتبر خطر منخفض.
        :param medium_to_high_threshold: ما فوقها يعتبر خطر عالي.
        """
        self.model_path = model_path
        self.low_to_medium_threshold = low_to_medium_threshold
        self.medium_to_high_threshold = medium_to_high_threshold




        try:
            self.pipeline = joblib.load(model_path)
        except FileNotFoundError:
            self.pipeline = None
            print(
                f"[WARNING] لم يتم العثور على {model_path}. "
                f"سيتم استخدام قواعد بسيطة لحساب المخاطر (rule-based)."
            )



    # --------- منطق تحويل الحدث إلى DataFrame جاهز للـ model ---------



    def _build_feature_frame(self, event: LoginEvent) -> pd.DataFrame:
        """
        يحول LoginEvent إلى DataFrame بصف واحدة جاهزة للـ pipeline.
        خلي أسماء الأعمدة هنا نفس اللي استخدمتيها وقت التدريب.
        """
        # ملاحظة: نحط نفس أسماء الأعمدة المستخدمة في التدريب
        data = {
            "hour_of_day": [event.hour_of_day],
            "weekday": [event.weekday],
            "failed_logins_last_24h": [event.failed_logins_last_24h],
            "typing_speed_cps": [event.typing_speed_cps],
            "nav_pattern_similarity": [event.nav_pattern_similarity],
            "session_duration_sec": [event.session_duration_sec],
            "distance_from_last_login_km": [event.distance_from_last_login_km],
            "is_vpn": [event.is_vpn],
            "is_new_device": [event.is_new_device],
            "is_new_city": [event.is_new_city],
            "past_compromised_account": [event.past_compromised_account],
            # ممكن تضيفين ميزات إضافية هنا لو استخدمتيها في التدريب
        }
        return pd.DataFrame(data)



    # --------- حساب درجة الخطر ---------



    def _predict_risk_ml(self, features: pd.DataFrame) -> float:
        """
        يستخدم الـ pipeline المدرب لحساب احتمالية أن تكون المحاولة هجوم (label=1).
        """
        if self.pipeline is None:
            raise RuntimeError("لا يوجد نموذج ML محمّل، سيتم استخدام القواعد اليدوية (rule-based).")



        # نفترض أن الـ pipeline يدعم predict_proba
        proba = self.pipeline.predict_proba(features)[0, 1]
        return float(proba)



    def _predict_risk_rule_based(self, event: LoginEvent) -> float:
        """
        بديل بسيط في حال ما كان عندنا نموذج ML جاهز.
        نحسب risk_score يدويًا من بعض الإشارات.
        """
        score = 0.0



        # جهاز جديد أو مدينة جديدة يرفع الخطر
        if event.is_new_device:
            score += 0.25
        if event.is_new_city:
            score += 0.2



        # استخدام VPN
        if event.is_vpn:
            score += 0.2



        # حسابات مخترقة سابقًا
        if event.past_compromised_account:
            score += 0.3



        # عدد المحاولات الفاشلة خلال 24 ساعة
        if event.failed_logins_last_24h >= 3:
            score += 0.2
        elif event.failed_logins_last_24h == 2:
            score += 0.1



        # تشابه نمط التصفح (كلما قل التشابه، زاد الخطر)
        if event.nav_pattern_similarity < 0.5:
            score += 0.15
        elif event.nav_pattern_similarity < 0.7:
            score += 0.1



        # مدة الجلسة القصيرة جدًا + سلوك غير طبيعي
        if event.session_duration_sec < 10:
            score += 0.1



        # ضمان أن السكور بين 0 و 1
        return float(max(0.0, min(1.0, score)))



    def _get_risk_level(self, risk_score: float) -> RiskLevelType:
        """
        تحويل risk_score إلى مستوى خطر نصي.
        """
        if risk_score < self.low_to_medium_threshold:
            return "low"
        elif risk_score < self.medium_to_high_threshold:
            return "medium"
        return "high"



    def _decide_action(self, risk_level: RiskLevelType) -> ActionType:
        """
        ماذا نفعل بناءً على مستوى الخطر؟
        """
        if risk_level == "low":
            return "allow"
        elif risk_level == "medium":
            # تحقق إضافي (OTP, FaceID, ...etc)
            return "step_up"
        else:
            # high
            return "block"



    def _build_reasons(self, event: LoginEvent, risk_score: float, risk_level: RiskLevelType) -> List[str]:
        """
        بناء قائمة أسباب تفسيرية (Explainability).
        """
        reasons: List[str] = []



        if event.is_new_device:
            reasons.append("محاولة تسجيل دخول من جهاز جديد.")
        if event.is_new_city:
            reasons.append("محاولة تسجيل دخول من مدينة جديدة.")
        if event.is_vpn:
            reasons.append("استخدام VPN أثناء تسجيل الدخول.")
        if event.failed_logins_last_24h > 0:
            reasons.append(f"{event.failed_logins_last_24h} محاولات فاشلة خلال آخر 24 ساعة.")
        if event.past_compromised_account:
            reasons.append("الحساب كان ضمن حسابات تم اختراقه سابقًا.")
        if event.nav_pattern_similarity < 0.7:
            reasons.append("نمط التنقل مختلف عن سلوك المستخدم المعتاد.")
        if event.session_duration_sec < 10:
            reasons.append("جلسة سريعة جدًا، قد تدل على نشاط آلي أو اختبار وصول فقط.")



        # لو ما فيه سبب واضح، نعطي جملة عامة
        if not reasons:
            reasons.append("المخاطر منخفضة ولا توجد إشارات سلوكية مقلقة.")



        # إضافة ملخص رقمي
        reasons.append(f"درجة الخطر المحسوبة: {risk_score:.2f} (مستوى: {risk_level}).")



        return reasons



    # --------- الدالة الرئيسية للوكيل ---------



    def assess_login(self, event: LoginEvent) -> SecurityDecision:
        """
        الدالة الأساسية اللي تستدعيها من أي مكان (API / Streamlit / Flask / إلخ).
        ترجع SecurityDecision جاهزة للعرض أو التخزين في Logs.
        """
        # نحضّر البيانات
        features = self._build_feature_frame(event)



        # نحسب درجة الخطر
        if self.pipeline is not None:
            risk_score = self._predict_risk_ml(features)
        else:
            risk_score = self._predict_risk_rule_based(event)



        risk_level = self._get_risk_level(risk_score)
        action = self._decide_action(risk_level)
        reasons = self._build_reasons(event, risk_score, risk_level)



        metadata: Dict[str, Any] = {
            "event_id": event.event_id,
            "user_id": event.user_id,
            "device_id": event.device_id,
            "device_type": event.device_type,
            "city": event.city,
            "country": event.country,
        }



        return SecurityDecision(
            action=action,
            risk_score=risk_score,
            risk_level=risk_level,
            reasons=reasons,
            metadata=metadata,
        )




# --------- مثال تشغيل محلي (للتجربة في كولاب) ---------



if __name__ == "__main__":

    """
    مثال بسيط:
    - نقرأ أول صف من ملف CSV
    - نحوله لـ LoginEvent
    - نخلي الوكيل يقيمه
    - نطبع القرار
    """



    # غيّري اسم الملف حسب اسم ملفك الفعلي
    csv_path = "yaqith_sentinel_synthetic_logins 2.xlsx"  # Updated to .xlsx



    try:
        df = pd.read_excel(csv_path) # Changed to pd.read_excel
    except FileNotFoundError:
        raise SystemExit(
            f"لم يتم العثور على الملف {csv_path}. "
            f"تأكدي من اسم الملف أو عدّلي المسار داخل الكود."
        )



    # نأخذ أول حدث كتجربة
    row = df.iloc[0]
    event = LoginEvent.from_row(row)



    agent = YAQITHSentinelAgent(
        model_path="risk_model_pipeline.joblib",
        low_to_medium_threshold=0.3,
        medium_to_high_threshold=0.7,
    )



    decision = agent.assess_login(event)



    print("=== Security Decision ===")
    print(f"Action     : {decision.action}")
    print(f"Risk score : {decision.risk_score:.3f}")
    print(f"Risk level : {decision.risk_level}")
    print("Reasons:")
    for r in decision.reasons:
        print(f"- {r}")
    print("Metadata:", decision.metadata)